# ğŸ¥ HealthFlow-MS

**Plateforme intelligente d'analyse de risque mÃ©dical basÃ©e sur des microservices**

[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docs.docker.com/compose/)
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.2-green.svg)](https://spring.io/projects/spring-boot)
[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-Event%20Streaming-orange.svg)](https://kafka.apache.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ï¿½ Vue d'ensemble

HealthFlow-MS est une plateforme MLOps complÃ¨te conÃ§ue pour l'analyse de risque mÃ©dical en temps rÃ©el. Elle traite les donnÃ©es FHIR R4, applique des algorithmes d'intelligence artificielle pour prÃ©dire les risques de santÃ©, et fournit des explications interprÃ©tables pour soutenir les dÃ©cisions cliniques.

### ğŸ¯ Objectifs principaux

- **Ingestion FHIR** : Traitement standardisÃ© des donnÃ©es mÃ©dicales
- **Pseudonymisation** : Protection de la vie privÃ©e conforme HIPAA/GDPR
- **IA MÃ©dicale** : PrÃ©diction de risques avec modÃ¨les XGBoost et BioBERT
- **ExplicabilitÃ©** : Visualisations SHAP pour l'interprÃ©tabilitÃ© des modÃ¨les
- **Monitoring** : Surveillance de la dÃ©rive des donnÃ©es et de l'Ã©quitÃ© des algorithmes

## ğŸ—ï¸ Architecture du SystÃ¨me

### Architecture Microservices Event-Driven

```mermaid
graph TB
    FHIR[Serveur FHIR Externe] --> ProxyFHIR[ProxyFHIR Service]
    ProxyFHIR --> PostgreSQL[(PostgreSQL)]
    ProxyFHIR --> Kafka1[fhir.data.raw]
    
    Kafka1 --> DeID[DeID Service]
    DeID --> PostgreSQL
    DeID --> Kafka2[fhir.data.anonymized]
    
    Kafka2 --> Featurizer[Featurizer Service]
    Featurizer --> Kafka3[features.patient.ready]
    
    Kafka3 --> ModelRisque[ModelRisque Service]
    ModelRisque --> PostgreSQL
    ModelRisque --> Kafka4[risk.score.calculated]
    
    PostgreSQL --> ScoreAPI[ScoreAPI Service]
    PostgreSQL --> AuditFairness[AuditFairness Dashboard]
    
    ScoreAPI --> WebApp[Applications Cliniques]
    AuditFairness --> DataScientist[Data Scientists]
```

### ğŸ“Š Flux de DonnÃ©es

1. **ProxyFHIR** â†’ Ingestion des donnÃ©es FHIR et publication dans `fhir.data.raw`
2. **DeID** â†’ Consommation, anonymisation et publication dans `fhir.data.anonymized`
3. **Featurizer** â†’ Extraction NLP/stats et publication dans `features.patient.ready`
4. **ModelRisque** â†’ PrÃ©diction ML et stockage en base + publication d'alertes
5. **ScoreAPI** â†’ Exposition REST sÃ©curisÃ©e des rÃ©sultats
6. **AuditFairness** â†’ Monitoring continu de l'Ã©quitÃ© et dÃ©rive

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis

- Docker Engine 20.10+
- Docker Compose 2.0+
- 8GB RAM minimum
- 20GB espace disque

### Installation

1. **Cloner le repository**
```bash
git clone https://github.com/your-org/HealthFlow-MS.git
cd HealthFlow-MS
```

2. **Lancer l'environnement complet**
```bash
docker-compose up -d
```

3. **VÃ©rifier le statut des services**
```bash
docker-compose ps
```

4. **AccÃ©der aux interfaces**
- **ScoreAPI Documentation** : http://localhost:8082/docs
- **AuditFairness Dashboard** : http://localhost:8083
- **ProxyFHIR Health** : http://localhost:8081/api/v1/fhir/health

### ğŸ§ª Test du Pipeline Complet

1. **Obtenir un token d'authentification**
```bash
curl -X POST http://localhost:8082/auth/token
```

2. **IngÃ©rer des donnÃ©es FHIR**
```bash
curl -X POST http://localhost:8081/api/v1/fhir/sync/patient/123 \
  -H "Content-Type: application/json"
```

3. **VÃ©rifier le score de risque** (aprÃ¨s quelques minutes)
```bash
curl -X GET http://localhost:8082/api/v1/score/PATIENT_XXXXXX \
  -H "Authorization: Bearer YOUR_TOKEN"
```

4. **AccÃ©der aux explications**
```bash
curl -X GET http://localhost:8082/api/v1/explain/PATIENT_XXXXXX \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## ğŸ“‹ Services DÃ©taillÃ©s

### 1. ProxyFHIR (Java/Spring Boot)

**Port** : 8081 | **ResponsabilitÃ©** : Ingestion FHIR

#### Endpoints Principaux
- `POST /api/v1/fhir/sync/patient/{id}` - Synchroniser un patient
- `POST /api/v1/fhir/sync/patients` - Synchronisation batch
- `GET /api/v1/fhir/health` - Health check

#### Configuration
```properties
# application.properties
fhir.server.base-url=https://hapi.fhir.org/baseR4
spring.datasource.url=jdbc:postgresql://postgres:5432/healthflow
spring.kafka.bootstrap-servers=kafka:9092
```

### 2. DeID (Python)

**ResponsabilitÃ©** : Anonymisation des donnÃ©es FHIR

#### FonctionnalitÃ©s
- Pseudonymisation cohÃ©rente avec Faker
- Mapping persistant des identifiants
- Support FHIR R4 complet
- PrÃ©servation de la structure des donnÃ©es

#### Variables d'Environnement
```bash
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
POSTGRES_HOST=postgres
DEID_SALT=healthflow-deid-salt-2024
```

### 3. Featurizer (Python/NLP)

**ResponsabilitÃ©** : Extraction de features mÃ©dicales

#### Technologies UtilisÃ©es
- **BioBERT** : Embeddings contextuels mÃ©dicaux
- **spaCy sci** : EntitÃ©s mÃ©dicales nommÃ©es
- **Statistiques** : AgrÃ©gation des signes vitaux
- **Features temporelles** : Tendances et Ã©volutions

#### Features Extraites
- DÃ©mographiques (Ã¢ge, genre, statut marital)
- Conditions mÃ©dicales (comptages par catÃ©gorie)
- MÃ©dicaments (classes thÃ©rapeutiques)
- Signes vitaux (moyennes, tendances, valeurs rÃ©centes)
- EntitÃ©s NLP (symptÃ´mes, maladies, traitements)
- Embeddings BioBERT (reprÃ©sentation sÃ©mantique)

### 4. ModelRisque (Python/ML)

**ResponsabilitÃ©** : PrÃ©diction de risque avec explicabilitÃ©

#### ModÃ¨le ML
- **Algorithme** : XGBoost Classifier
- **ExplicabilitÃ©** : SHAP TreeExplainer
- **MÃ©triques** : Score de risque (0-1) + niveau de confiance
- **CatÃ©gories** : LOW, MODERATE, HIGH, CRITICAL

#### Pipeline de PrÃ©diction
1. PrÃ©paration du vecteur de features
2. Normalisation avec StandardScaler
3. PrÃ©diction XGBoost
4. Calcul des valeurs SHAP
5. GÃ©nÃ©ration d'explications textuelles
6. Persistance en base de donnÃ©es

### 5. ScoreAPI (Python/FastAPI)

**Port** : 8082 | **ResponsabilitÃ©** : API REST sÃ©curisÃ©e

#### SÃ©curitÃ©
- **Authentification** : JWT Bearer tokens
- **Autorisation** : Middleware de vÃ©rification
- **CORS** : Configuration pour applications web
- **Rate Limiting** : Protection contre les abus

#### Endpoints API

##### Authentification
```bash
POST /auth/token
```
**RÃ©ponse** :
```json
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
  "token_type": "bearer",
  "expires_in": 1800
}
```

##### Score de Risque
```bash
GET /api/v1/score/{patient_pseudo_id}
Authorization: Bearer {token}
```
**RÃ©ponse** :
```json
{
  "patient_pseudo_id": "PATIENT_123456",
  "risk_score": 0.75,
  "prediction_confidence": 0.89,
  "risk_level": "HIGH",
  "model_version": "v1.0",
  "prediction_timestamp": "2024-01-15T10:30:00Z",
  "created_at": "2024-01-15T10:30:05Z"
}
```

##### Explications SHAP
```bash
GET /api/v1/explain/{patient_pseudo_id}
Authorization: Bearer {token}
```
**RÃ©ponse** :
```json
{
  "patient_pseudo_id": "PATIENT_123456",
  "risk_score": 0.75,
  "shap_values": {
    "age": 0.12,
    "total_conditions": 0.08,
    "heart_rate_mean": 0.05
  },
  "top_risk_factors": ["age", "total_conditions", "heart_rate_mean"],
  "explanation_text": "Key risk factors: Age increases risk (impact: 0.120); Total Conditions increases risk (impact: 0.080)",
  "model_version": "v1.0",
  "prediction_timestamp": "2024-01-15T10:30:00Z"
}
```

##### Statistiques
```bash
GET /api/v1/statistics/summary
GET /api/v1/scores/recent?limit=50
GET /api/v1/scores/high-risk?threshold=0.7
```

### 6. AuditFairness (Python/Dash)

**Port** : 8083 | **ResponsabilitÃ©** : Dashboard de monitoring

#### FonctionnalitÃ©s de Monitoring

##### MÃ©triques d'Ã‰quitÃ©
- **Disparate Impact** : Ratio des taux de risque Ã©levÃ© par groupe dÃ©mographique
- **Equal Opportunity** : Ã‰galitÃ© des vrais positifs
- **Demographic Parity** : Distribution Ã©quitable des prÃ©dictions

##### DÃ©tection de DÃ©rive
- **Data Drift** : Ã‰volution des distributions de features
- **Concept Drift** : Changement des relations input-output
- **Population Shift** : Modification des caractÃ©ristiques dÃ©mographiques

##### Visualisations
- Distribution des scores de risque
- Tendances temporelles
- Analyse par groupes dÃ©mographiques
- Rapports de dÃ©rive EvidentlyAI

## ğŸ—„ï¸ Base de DonnÃ©es PostgreSQL

### SchÃ©ma Principal

#### Table `fhir_bundles`
```sql
CREATE TABLE fhir_bundles (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    patient_id VARCHAR(255) NOT NULL,
    bundle_type VARCHAR(100) NOT NULL DEFAULT 'Patient',
    bundle_data JSONB NOT NULL,
    original_data_hash VARCHAR(64),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### Table `pseudonym_mapping`
```sql
CREATE TABLE pseudonym_mapping (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    original_identifier VARCHAR(500) NOT NULL,
    pseudonym_identifier VARCHAR(500) NOT NULL,
    identifier_type VARCHAR(100) NOT NULL,
    salt_used VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### Table `prediction_results`
```sql
CREATE TABLE prediction_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    patient_pseudo_id VARCHAR(255) NOT NULL,
    risk_score DECIMAL(5,4) NOT NULL CHECK (risk_score >= 0.0 AND risk_score <= 1.0),
    prediction_confidence DECIMAL(5,4),
    shap_values_json JSONB,
    feature_vector_json JSONB,
    model_version VARCHAR(50) DEFAULT 'v1.0',
    prediction_timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### Table `audit_logs`
```sql
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    service_name VARCHAR(100) NOT NULL,
    operation_type VARCHAR(100) NOT NULL,
    patient_pseudo_id VARCHAR(255),
    operation_metadata JSONB,
    execution_time_ms INTEGER,
    status VARCHAR(50) DEFAULT 'success',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ”§ Configuration et Personnalisation

### Variables d'Environnement Importantes

#### SÃ©curitÃ©
```bash
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
DEID_SALT=healthflow-deid-salt-2024
```

#### Connexions Base de DonnÃ©es
```bash
POSTGRES_HOST=postgres
POSTGRES_DB=healthflow
POSTGRES_USER=healthflow
POSTGRES_PASSWORD=healthflow123
```

#### Kafka
```bash
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
```

#### Serveur FHIR
```bash
FHIR_SERVER_BASE_URL=https://hapi.fhir.org/baseR4
```

### Personnalisation du ModÃ¨le ML

Pour utiliser votre propre modÃ¨le :

1. **EntraÃ®ner le modÃ¨le** avec vos donnÃ©es
2. **Sauvegarder les artifacts** :
   ```python
   # Sauvegarder le modÃ¨le XGBoost
   model.save_model('/path/to/model.xgb')
   
   # Sauvegarder l'explainer SHAP
   with open('/path/to/explainer.pkl', 'wb') as f:
       pickle.dump(explainer, f)
   
   # Sauvegarder le scaler
   with open('/path/to/scaler.pkl', 'wb') as f:
       pickle.dump(scaler, f)
   ```

3. **Monter les fichiers** dans le conteneur ModelRisque
4. **Mettre Ã  jour** la configuration du modÃ¨le

### Configuration des Features NLP

Pour personnaliser l'extraction de features :

1. **Modifier les concepts mÃ©dicaux** dans `featurizer/app/main.py`
2. **Ajouter de nouveaux modÃ¨les** NLP
3. **Personnaliser les features** dÃ©mographiques et cliniques

## ğŸ“Š Monitoring et ObservabilitÃ©

### MÃ©triques Disponibles

#### MÃ©triques MÃ©tier
- Nombre de prÃ©dictions par jour
- Distribution des scores de risque
- Taux de patients Ã  haut risque
- Temps de traitement par patient

#### MÃ©triques Techniques
- Latence des APIs
- Throughput Kafka
- Utilisation CPU/MÃ©moire
- Erreurs par service

#### MÃ©triques de QualitÃ© ML
- DÃ©rive des donnÃ©es d'entrÃ©e
- StabilitÃ© des prÃ©dictions
- MÃ©triques d'Ã©quitÃ©
- Confidence des prÃ©dictions

### Alerting

Le systÃ¨me gÃ©nÃ¨re des alertes pour :
- Patients Ã  risque critique (score > 0.8)
- DÃ©rive de donnÃ©es dÃ©tectÃ©e
- Biais dÃ©mographiques identifiÃ©s
- Erreurs systÃ¨me critiques

## ğŸ”’ SÃ©curitÃ© et ConformitÃ©

### Anonymisation des DonnÃ©es

- **Pseudonymisation** : Remplacement cohÃ©rent des identifiants
- **Suppression** : Ã‰limination des adresses et contacts
- **Hachage** : Protection cryptographique des mappings
- **Audit Trail** : TraÃ§abilitÃ© complÃ¨te des transformations

### ConformitÃ© RGPD/HIPAA

- **Privacy by Design** : Anonymisation dÃ¨s l'ingestion
- **Data Minimization** : Collecte uniquement des donnÃ©es nÃ©cessaires
- **Right to be Forgotten** : CapacitÃ© de suppression
- **Access Control** : Authentification et autorisation

### SÃ©curitÃ© API

- **JWT Authentication** : Tokens signÃ©s et expirables
- **HTTPS Only** : Chiffrement en transit
- **Rate Limiting** : Protection contre les abus
- **Input Validation** : Validation stricte des entrÃ©es

## ğŸ§ª Tests et Validation

### Tests Fonctionnels

```bash
# Test du pipeline complet
./scripts/test_pipeline.sh

# Test des APIs
./scripts/test_apis.sh

# Test de charge
./scripts/load_test.sh
```

### Validation du ModÃ¨le

```bash
# MÃ©triques de performance
./scripts/validate_model.sh

# Tests d'Ã©quitÃ©
./scripts/fairness_test.sh

# Tests de robustesse
./scripts/robustness_test.sh
```

## ğŸ”§ DÃ©pannage

### ProblÃ¨mes Courants

#### Services qui ne dÃ©marrent pas
```bash
# VÃ©rifier les logs
docker-compose logs [service-name]

# RedÃ©marrer un service
docker-compose restart [service-name]

# Reconstruire les images
docker-compose build [service-name]
```

#### ProblÃ¨mes de connectivitÃ© Kafka
```bash
# VÃ©rifier les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# VÃ©rifier les consumers
docker-compose exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list
```

#### ProblÃ¨mes de base de donnÃ©es
```bash
# Connexion Ã  PostgreSQL
docker-compose exec postgres psql -U healthflow -d healthflow

# VÃ©rifier les tables
\dt

# VÃ©rifier les donnÃ©es
SELECT COUNT(*) FROM prediction_results;
```

### Logs et Debugging

Les logs sont disponibles via :
```bash
# Logs en temps rÃ©el
docker-compose logs -f

# Logs d'un service spÃ©cifique
docker-compose logs -f proxyfhir

# Logs avec timestamp
docker-compose logs -t
```

## ğŸ“ˆ Performance et ScalabilitÃ©

### Optimisations RecommandÃ©es

#### Production Ready
1. **Load Balancer** : HAProxy ou NGINX
2. **Database Cluster** : PostgreSQL HA
3. **Kafka Cluster** : Multi-broker setup
4. **Monitoring** : Prometheus + Grafana
5. **Logging** : ELK Stack

#### Scaling Horizontal
```yaml
# docker-compose.override.yml
version: '3.8'
services:
  featurizer:
    scale: 3
  modelrisque:
    scale: 2
  scoreapi:
    scale: 3
```

#### Optimisations Kafka
- Partitioning par patient_id
- Compression des messages
- Batch processing
- Consumer groups dÃ©diÃ©s

## ğŸ¤ Contribution

### Structure du Projet

```
HealthFlow-MS/
â”œâ”€â”€ docker-compose.yml          # Infrastructure complÃ¨te
â”œâ”€â”€ init-db/
â”‚   â””â”€â”€ init.sql               # SchÃ©mas PostgreSQL
â”œâ”€â”€ proxyfhir/                 # Service Java/Spring Boot
â”‚   â”œâ”€â”€ src/main/java/         # Code source Java
â”‚   â”œâ”€â”€ pom.xml               # DÃ©pendances Maven
â”‚   â””â”€â”€ Dockerfile            # Image Docker
â”œâ”€â”€ deid/                     # Service Python d'anonymisation
â”‚   â”œâ”€â”€ app/main.py          # Logic principale
â”‚   â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”‚   â””â”€â”€ Dockerfile           # Image Docker
â”œâ”€â”€ featurizer/              # Service d'extraction NLP
â”‚   â”œâ”€â”€ app/main.py         # Extraction de features
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances ML/NLP
â”‚   â””â”€â”€ Dockerfile          # Image Docker
â”œâ”€â”€ modelrisque/            # Service de prÃ©diction ML
â”‚   â”œâ”€â”€ app/main.py        # ModÃ¨le XGBoost + SHAP
â”‚   â”œâ”€â”€ model/             # Artifacts du modÃ¨le
â”‚   â”œâ”€â”€ requirements.txt   # DÃ©pendances ML
â”‚   â””â”€â”€ Dockerfile         # Image Docker
â”œâ”€â”€ scoreapi/              # API REST FastAPI
â”‚   â”œâ”€â”€ app/main.py       # Endpoints sÃ©curisÃ©s
â”‚   â”œâ”€â”€ requirements.txt  # DÃ©pendances API
â”‚   â””â”€â”€ Dockerfile        # Image Docker
â”œâ”€â”€ auditfairness/        # Dashboard Dash
â”‚   â”œâ”€â”€ app/dashboard.py  # Interface de monitoring
â”‚   â”œâ”€â”€ requirements.txt  # DÃ©pendances dashboard
â”‚   â””â”€â”€ Dockerfile        # Image Docker
â””â”€â”€ README.md             # Documentation complÃ¨te
```

### Guidelines de DÃ©veloppement

1. **Code Quality** : Tests unitaires obligatoires
2. **Documentation** : Docstrings et commentaires
3. **Security** : Scan des vulnÃ©rabilitÃ©s
4. **Performance** : Profiling des services critiques

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™‹â€â™‚ï¸ Support

### Documentation SupplÃ©mentaire
- [Architecture Decision Records](docs/adr/)
- [API Documentation](docs/api/)
- [Deployment Guide](docs/deployment/)
- [Troubleshooting Guide](docs/troubleshooting/)

### Contacts
- **Ã‰quipe Technique** : tech-team@healthflow.com
- **Support** : support@healthflow.com
- **SÃ©curitÃ©** : security@healthflow.com

---

**HealthFlow-MS** - *Transforming Healthcare through Intelligent Risk Assessment*