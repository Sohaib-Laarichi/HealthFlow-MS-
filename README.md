# üè• HealthFlow-MS

**Plateforme intelligente d'analyse de risque m√©dical bas√©e sur des microservices**

[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docs.docker.com/compose/)
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.2-green.svg)](https://spring.io/projects/spring-boot)
[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-Event%20Streaming-orange.svg)](https://kafka.apache.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## üó∫Ô∏è Vue d'ensemble

HealthFlow-MS est une plateforme MLOps compl√®te con√ßue pour l'analyse de risque m√©dical en temps r√©el. Elle traite les donn√©es FHIR R4, applique des algorithmes d'intelligence artificielle pour pr√©dire les risques de sant√©, et fournit des explications interpr√©tables pour soutenir les d√©cisions cliniques.

### üéØ Objectifs principaux

- **Ingestion FHIR** : Traitement standardis√© des donn√©es m√©dicales
- **Pseudonymisation** : Protection de la vie priv√©e conforme HIPAA/GDPR
- **IA M√©dicale** : Pr√©diction de risques avec mod√®les XGBoost et BioBERT
- **Explicabilit√©** : Visualisations SHAP pour l'interpr√©tabilit√© des mod√®les
- **Monitoring** : Surveillance de la d√©rive des donn√©es et de l'√©quit√© des algorithmes

## üÜï Mises √† jour r√©centes (2025-10)

- Docker Compose: commandes mises √† jour vers `docker compose` (v2) et ajout de `--build` lors du premier lancement.
- Kafka: configuration d‚Äô√©couteurs annonc√©s corrig√©e pour un fonctionnement inter-conteneurs (`PLAINTEXT://kafka:9092, PLAINTEXT_HOST://localhost:9094`).
- ProxyFHIR: image runtime durcie, healthcheck via Actuator, et client FHIR initialis√© au d√©marrage.
- ScoreAPI: healthcheck bas√© sur curl dans le conteneur, docs disponibles sur `/docs`.
- AuditFairness: design modernis√© (th√®me Bootstrap Minty, navbar, cartes, loaders, footer).
- D√©pendances Python: corrections mineures (evidently compatible Pydantic v2, renommage `python-dateutil`, suppression d‚Äôentr√©es stdlib erron√©es).

Voir TROUBLESHOOTING.md pour les conseils de d√©bogage courants.

## üèóÔ∏è Architecture du Syst√®me

### Architecture Microservices Event-Driven

```mermaid
graph TB
    FHIR[Serveur FHIR Externe] --> ProxyFHIR[ProxyFHIR Service]
    ProxyFHIR --> PostgreSQL[(PostgreSQL)]
    ProxyFHIR --> Kafka1[fhir.data.raw]
    
    Kafka1 --> DeID[DeID Service]
    DeID --> PostgreSQL
    DeID --> Kafka2[fhir.data.anonymized]
    
    Kafka2 --> Featurizer[Featurizer Service]
    Featurizer --> Kafka3[features.patient.ready]
    
    Kafka3 --> ModelRisque[ModelRisque Service]
    ModelRisque --> PostgreSQL
    ModelRisque --> Kafka4[risk.score.calculated]
    
    PostgreSQL --> ScoreAPI[ScoreAPI Service]
    PostgreSQL --> AuditFairness[AuditFairness Dashboard]
    
    ScoreAPI --> WebApp[Applications Cliniques]
    AuditFairness --> DataScientist[Data Scientists]
```

### üìä Flux de Donn√©es

1. **ProxyFHIR** ‚Üí Ingestion des donn√©es FHIR et publication dans `fhir.data.raw`
2. **DeID** ‚Üí Consommation, anonymisation et publication dans `fhir.data.anonymized`
3. **Featurizer** ‚Üí Extraction NLP/stats et publication dans `features.patient.ready`
4. **ModelRisque** ‚Üí Pr√©diction ML et stockage en base + publication d'alertes
5. **ScoreAPI** ‚Üí Exposition REST s√©curis√©e des r√©sultats
6. **AuditFairness** ‚Üí Monitoring continu de l'√©quit√© et d√©rive

## üöÄ D√©marrage Rapide

### Pr√©requis

- Docker Engine 20.10+
- Docker Compose 2.0+
- 8GB RAM minimum
- 20GB espace disque

### Installation

1. **Cloner le repository**
```bash
git clone https://github.com/your-org/HealthFlow-MS.git
cd HealthFlow-MS
```

2. **Lancer l'environnement complet**
```bash
docker compose up -d --build
```

3. **V√©rifier le statut des services**
```bash
docker compose ps
```

4. **Acc√©der aux interfaces**
- **ScoreAPI Documentation** : http://localhost:8082/docs
- **AuditFairness Dashboard** : http://localhost:8083
- **DataManager (gestion des donn√©es)** : http://localhost:8084/docs
- **ProxyFHIR Health** : http://localhost:8081/api/v1/fhir/health

## üîó Liens utiles

- Frontends et APIs
  - AuditFairness Dashboard: http://localhost:8083
  - DataManager (CRUD des donn√©es): http://localhost:8084/docs
  - ScoreAPI OpenAPI Docs: http://localhost:8082/docs
  - ScoreAPI ReDoc: http://localhost:8082/redoc
  - ScoreAPI Health: http://localhost:8082/health
  - ProxyFHIR Health: http://localhost:8081/api/v1/fhir/health
  - ProxyFHIR Actuator (health): http://localhost:8081/actuator/health
  - ProxyFHIR Prometheus metrics: http://localhost:8081/actuator/prometheus

- Infrastructure
  - Kafka (interne, pour services): kafka:9092
  - Kafka (h√¥te, pour tests locaux): localhost:9094
  - Kafka Topics: `fhir.data.raw`, `fhir.data.anonymized`, `features.patient.ready`, `risk.score.calculated`
  - PostgreSQL: postgres:5432 (h√¥te: localhost:5432)
  - Base de donn√©es: healthflow | Utilisateur: healthflow | Mot de passe: healthflow123

- Documentation
  - README (pr√©sent document)
  - D√©pannage: TROUBLESHOOTING.md
  - Vue d‚Äôensemble: PROJECT_OVERVIEW.md
  - √âtat du projet: PROJECT_STATUS.md

## üì° Donn√©es du dashboard depuis HAPI FHIR

Pour que le dashboard affiche des donn√©es r√©elles issues de HAPI FHIR (https://hapi.fhir.org/baseR4/), suivez ces √©tapes:

1) D√©marrer la stack
- docker compose up -d --build

2) D√©sactiver le mode d√©mo du dashboard (d√©j√† configur√© par d√©faut)
- Le service AuditFairness est lanc√© avec DASH_DEMO_MODE=0 dans docker-compose.yml, il n'affichera donc que les donn√©es r√©elles pr√©sentes en base.

3) Ing√©rer un patient r√©el depuis HAPI FHIR
- Choisir un Patient ID valide visible sur https://hapi.fhir.org/baseR4
- Lancer l'ingestion via ProxyFHIR:
  - curl -X POST http://localhost:8081/api/v1/fhir/sync/patient/<PATIENT_ID>

4) Laisser le pipeline traiter
- DeID anonymise ‚Üí Featurizer extrait les features ‚Üí ModelRisque calcule le score et √©crit dans PostgreSQL (prediction_results).
- Suivre les logs si besoin:
  - docker compose logs -f deid featurizer modelrisque

5) Consulter les r√©sultats
- ScoreAPI: http://localhost:8082/docs (GET /api/v1/score/{patient_pseudo_id})
- Dashboard: http://localhost:8083 (les graphiques doivent refl√©ter les donn√©es r√©elles)

Astuce: si aucune donn√©e n‚Äôappara√Æt, v√©rifiez que le Patient ID existe bien sur HAPI et patientez quelques instants le temps que le pipeline termine le traitement.

## ‚ôªÔ∏è Voir le nouveau dashboard (rebuild)

Si vous avez modifi√© le code du dashboard AuditFairness et que l‚Äôinterface ne refl√®te pas les changements, reconstruisez uniquement ce service sans cache puis red√©marrez-le.

Commandes rapides:
```bash
# Depuis la racine du repo
docker compose build --no-cache auditfairness
docker compose up -d auditfairness
```

Ou utilisez le script d‚Äôaide:
```bash
bash scripts/rebuild_dashboard.sh
```

Astuces:
- Rafra√Æchissez le navigateur avec un hard‚Äëreload (Ctrl+F5) pour √©viter le cache.
- Consultez les logs du service pour v√©rifier le d√©marrage:
  ```bash
  docker compose logs -f --tail=100 auditfairness
  ```
- Si des d√©pendances Python ont chang√©, ex√©cutez la reconstruction compl√®te au premier essai.

### üß™ Test du Pipeline Complet

1. **Obtenir un token d'authentification**
```bash
curl -X POST http://localhost:8082/auth/token
```

2. **Ing√©rer des donn√©es FHIR**
```bash
curl -X POST http://localhost:8081/api/v1/fhir/sync/patient/123 \
  -H "Content-Type: application/json"
```

3. **V√©rifier le score de risque** (apr√®s quelques minutes)
```bash
curl -X GET http://localhost:8082/api/v1/score/PATIENT_XXXXXX \
  -H "Authorization: Bearer YOUR_TOKEN"
```

4. **Acc√©der aux explications**
```bash
curl -X GET http://localhost:8082/api/v1/explain/PATIENT_XXXXXX \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## üìã Services D√©taill√©s

### 1. ProxyFHIR (Java/Spring Boot)

**Port** : 8081 | **Responsabilit√©** : Ingestion FHIR

#### Endpoints Principaux
- `POST /api/v1/fhir/sync/patient/{id}` - Synchroniser un patient
- `POST /api/v1/fhir/sync/patients` - Synchronisation batch
- `GET /api/v1/fhir/health` - Health check

#### Configuration
```properties
# application.properties
fhir.server.base-url=https://hapi.fhir.org/baseR4
spring.datasource.url=jdbc:postgresql://postgres:5432/healthflow
spring.kafka.bootstrap-servers=kafka:9092
```

### 2. DeID (Python)

**Responsabilit√©** : Anonymisation des donn√©es FHIR

#### Fonctionnalit√©s
- Pseudonymisation coh√©rente avec Faker
- Mapping persistant des identifiants
- Support FHIR R4 complet
- Pr√©servation de la structure des donn√©es

#### Variables d'Environnement
```bash
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
POSTGRES_HOST=postgres
DEID_SALT=healthflow-deid-salt-2024
```

### 3. Featurizer (Python/NLP)

**Responsabilit√©** : Extraction de features m√©dicales

#### Technologies Utilis√©es
- **BioBERT** : Embeddings contextuels m√©dicaux
- **spaCy sci** : Entit√©s m√©dicales nomm√©es
- **Statistiques** : Agr√©gation des signes vitaux
- **Features temporelles** : Tendances et √©volutions

#### Features Extraites
- D√©mographiques (√¢ge, genre, statut marital)
- Conditions m√©dicales (comptages par cat√©gorie)
- M√©dicaments (classes th√©rapeutiques)
- Signes vitaux (moyennes, tendances, valeurs r√©centes)
- Entit√©s NLP (sympt√¥mes, maladies, traitements)
- Embeddings BioBERT (repr√©sentation s√©mantique)

### 4. ModelRisque (Python/ML)

**Responsabilit√©** : Pr√©diction de risque avec explicabilit√©

#### Mod√®le ML
- **Algorithme** : XGBoost Classifier
- **Explicabilit√©** : SHAP TreeExplainer
- **M√©triques** : Score de risque (0-1) + niveau de confiance
- **Cat√©gories** : LOW, MODERATE, HIGH, CRITICAL

#### Pipeline de Pr√©diction
1. Pr√©paration du vecteur de features
2. Normalisation avec StandardScaler
3. Pr√©diction XGBoost
4. Calcul des valeurs SHAP
5. G√©n√©ration d'explications textuelles
6. Persistance en base de donn√©es

### 5. ScoreAPI (Python/FastAPI)

**Port** : 8082 | **Responsabilit√©** : API REST s√©curis√©e

#### S√©curit√©
- **Authentification** : JWT Bearer tokens
- **Autorisation** : Middleware de v√©rification
- **CORS** : Configuration pour applications web
- **Rate Limiting** : Protection contre les abus

#### Endpoints API

##### Authentification
```bash
POST /auth/token
```
**R√©ponse** :
```json
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
  "token_type": "bearer",
  "expires_in": 1800
}
```

##### Score de Risque
```bash
GET /api/v1/score/{patient_pseudo_id}
Authorization: Bearer {token}
```
**R√©ponse** :
```json
{
  "patient_pseudo_id": "PATIENT_123456",
  "risk_score": 0.75,
  "prediction_confidence": 0.89,
  "risk_level": "HIGH",
  "model_version": "v1.0",
  "prediction_timestamp": "2024-01-15T10:30:00Z",
  "created_at": "2024-01-15T10:30:05Z"
}
```

##### Explications SHAP
```bash
GET /api/v1/explain/{patient_pseudo_id}
Authorization: Bearer {token}
```
**R√©ponse** :
```json
{
  "patient_pseudo_id": "PATIENT_123456",
  "risk_score": 0.75,
  "shap_values": {
    "age": 0.12,
    "total_conditions": 0.08,
    "heart_rate_mean": 0.05
  },
  "top_risk_factors": ["age", "total_conditions", "heart_rate_mean"],
  "explanation_text": "Key risk factors: Age increases risk (impact: 0.120); Total Conditions increases risk (impact: 0.080)",
  "model_version": "v1.0",
  "prediction_timestamp": "2024-01-15T10:30:00Z"
}
```

##### Statistiques
```bash
GET /api/v1/statistics/summary
GET /api/v1/scores/recent?limit=50
GET /api/v1/scores/high-risk?threshold=0.7
```

### 6. AuditFairness (Python/Dash)

**Port** : 8083 | **Responsabilit√©** : Dashboard de monitoring

#### Fonctionnalit√©s de Monitoring

##### M√©triques d'√âquit√©
- **Disparate Impact** : Ratio des taux de risque √©lev√© par groupe d√©mographique
- **Equal Opportunity** : √âgalit√© des vrais positifs
- **Demographic Parity** : Distribution √©quitable des pr√©dictions

##### D√©tection de D√©rive
- **Data Drift** : √âvolution des distributions de features
- **Concept Drift** : Changement des relations input-output
- **Population Shift** : Modification des caract√©ristiques d√©mographiques

##### Visualisations
- Distribution des scores de risque
- Tendances temporelles
- Analyse par groupes d√©mographiques
- Rapports de d√©rive EvidentlyAI

## üóÑÔ∏è Base de Donn√©es PostgreSQL

### Sch√©ma Principal

#### Table `fhir_bundles`
```sql
CREATE TABLE fhir_bundles (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    patient_id VARCHAR(255) NOT NULL,
    bundle_type VARCHAR(100) NOT NULL DEFAULT 'Patient',
    bundle_data JSONB NOT NULL,
    original_data_hash VARCHAR(64),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### Table `pseudonym_mapping`
```sql
CREATE TABLE pseudonym_mapping (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    original_identifier VARCHAR(500) NOT NULL,
    pseudonym_identifier VARCHAR(500) NOT NULL,
    identifier_type VARCHAR(100) NOT NULL,
    salt_used VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### Table `prediction_results`
```sql
CREATE TABLE prediction_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    patient_pseudo_id VARCHAR(255) NOT NULL,
    risk_score DECIMAL(5,4) NOT NULL CHECK (risk_score >= 0.0 AND risk_score <= 1.0),
    prediction_confidence DECIMAL(5,4),
    shap_values_json JSONB,
    feature_vector_json JSONB,
    model_version VARCHAR(50) DEFAULT 'v1.0',
    prediction_timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### Table `audit_logs`
```sql
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    service_name VARCHAR(100) NOT NULL,
    operation_type VARCHAR(100) NOT NULL,
    patient_pseudo_id VARCHAR(255),
    operation_metadata JSONB,
    execution_time_ms INTEGER,
    status VARCHAR(50) DEFAULT 'success',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

## üîß Configuration et Personnalisation

### Variables d'Environnement Importantes

#### S√©curit√©
```bash
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
DEID_SALT=healthflow-deid-salt-2024
```

#### Connexions Base de Donn√©es
```bash
POSTGRES_HOST=postgres
POSTGRES_DB=healthflow
POSTGRES_USER=healthflow
POSTGRES_PASSWORD=healthflow123
```

#### Kafka
```bash
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
```

#### Serveur FHIR
```bash
FHIR_SERVER_BASE_URL=https://hapi.fhir.org/baseR4
```

### Personnalisation du Mod√®le ML

Pour utiliser votre propre mod√®le :

1. **Entra√Æner le mod√®le** avec vos donn√©es
2. **Sauvegarder les artifacts** :
   ```python
   # Sauvegarder le mod√®le XGBoost
   model.save_model('/path/to/model.xgb')
   
   # Sauvegarder l'explainer SHAP
   with open('/path/to/explainer.pkl', 'wb') as f:
       pickle.dump(explainer, f)
   
   # Sauvegarder le scaler
   with open('/path/to/scaler.pkl', 'wb') as f:
       pickle.dump(scaler, f)
   ```

3. **Monter les fichiers** dans le conteneur ModelRisque
4. **Mettre √† jour** la configuration du mod√®le

### Configuration des Features NLP

Pour personnaliser l'extraction de features :

1. **Modifier les concepts m√©dicaux** dans `featurizer/app/main.py`
2. **Ajouter de nouveaux mod√®les** NLP
3. **Personnaliser les features** d√©mographiques et cliniques

## üìä Monitoring et Observabilit√©

### M√©triques Disponibles

#### M√©triques M√©tier
- Nombre de pr√©dictions par jour
- Distribution des scores de risque
- Taux de patients √† haut risque
- Temps de traitement par patient

#### M√©triques Techniques
- Latence des APIs
- Throughput Kafka
- Utilisation CPU/M√©moire
- Erreurs par service

#### M√©triques de Qualit√© ML
- D√©rive des donn√©es d'entr√©e
- Stabilit√© des pr√©dictions
- M√©triques d'√©quit√©
- Confidence des pr√©dictions

### Alerting

Le syst√®me g√©n√®re des alertes pour :
- Patients √† risque critique (score > 0.8)
- D√©rive de donn√©es d√©tect√©e
- Biais d√©mographiques identifi√©s
- Erreurs syst√®me critiques

## üîí S√©curit√© et Conformit√©

### Anonymisation des Donn√©es

- **Pseudonymisation** : Remplacement coh√©rent des identifiants
- **Suppression** : √âlimination des adresses et contacts
- **Hachage** : Protection cryptographique des mappings
- **Audit Trail** : Tra√ßabilit√© compl√®te des transformations

### Conformit√© RGPD/HIPAA

- **Privacy by Design** : Anonymisation d√®s l'ingestion
- **Data Minimization** : Collecte uniquement des donn√©es n√©cessaires
- **Right to be Forgotten** : Capacit√© de suppression
- **Access Control** : Authentification et autorisation

### S√©curit√© API

- **JWT Authentication** : Tokens sign√©s et expirables
- **HTTPS Only** : Chiffrement en transit
- **Rate Limiting** : Protection contre les abus
- **Input Validation** : Validation stricte des entr√©es

## üß™ Tests et Validation

### Tests Fonctionnels

```bash
# Test du pipeline complet
./scripts/test_pipeline.sh

# Test des APIs
./scripts/test_apis.sh

# Test de charge
./scripts/load_test.sh
```

### Validation du Mod√®le

```bash
# M√©triques de performance
./scripts/validate_model.sh

# Tests d'√©quit√©
./scripts/fairness_test.sh

# Tests de robustesse
./scripts/robustness_test.sh
```

## üîß D√©pannage

### Probl√®mes Courants

#### Services qui ne d√©marrent pas
```bash
# V√©rifier les logs
docker-compose logs [service-name]

# Red√©marrer un service
docker-compose restart [service-name]

# Reconstruire les images
docker-compose build [service-name]
```

#### Probl√®mes de connectivit√© Kafka
```bash
# V√©rifier les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# V√©rifier les consumers
docker-compose exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list
```

#### Probl√®mes de base de donn√©es
```bash
# Connexion √† PostgreSQL
docker-compose exec postgres psql -U healthflow -d healthflow

# V√©rifier les tables
\dt

# V√©rifier les donn√©es
SELECT COUNT(*) FROM prediction_results;
```

### Logs et Debugging

Les logs sont disponibles via :
```bash
# Logs en temps r√©el
docker-compose logs -f

# Logs d'un service sp√©cifique
docker-compose logs -f proxyfhir

# Logs avec timestamp
docker-compose logs -t
```

## üìà Performance et Scalabilit√©

### Optimisations Recommand√©es

#### Production Ready
1. **Load Balancer** : HAProxy ou NGINX
2. **Database Cluster** : PostgreSQL HA
3. **Kafka Cluster** : Multi-broker setup
4. **Monitoring** : Prometheus + Grafana
5. **Logging** : ELK Stack

#### Scaling Horizontal
```bash
# Mise √† l'√©chelle avec Docker Compose v2 (exemples)
docker compose up -d --scale featurizer=3
docker compose up -d --scale modelrisque=2
docker compose up -d --scale scoreapi=3
```

#### Optimisations Kafka
- Partitioning par patient_id
- Compression des messages
- Batch processing
- Consumer groups d√©di√©s

## ü§ù Contribution

### Structure du Projet

```
HealthFlow-MS/
‚îú‚îÄ‚îÄ docker-compose.yml          # Infrastructure compl√®te
‚îú‚îÄ‚îÄ init-db/
‚îÇ   ‚îî‚îÄ‚îÄ init.sql               # Sch√©mas PostgreSQL
‚îú‚îÄ‚îÄ proxyfhir/                 # Service Java/Spring Boot
‚îÇ   ‚îú‚îÄ‚îÄ src/main/java/         # Code source Java
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml               # D√©pendances Maven
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile            # Image Docker
‚îú‚îÄ‚îÄ deid/                     # Service Python d'anonymisation
‚îÇ   ‚îú‚îÄ‚îÄ app/main.py          # Logic principale
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt     # D√©pendances Python
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile           # Image Docker
‚îú‚îÄ‚îÄ featurizer/              # Service d'extraction NLP
‚îÇ   ‚îú‚îÄ‚îÄ app/main.py         # Extraction de features
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt    # D√©pendances ML/NLP
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile          # Image Docker
‚îú‚îÄ‚îÄ modelrisque/            # Service de pr√©diction ML
‚îÇ   ‚îú‚îÄ‚îÄ app/main.py        # Mod√®le XGBoost + SHAP
‚îÇ   ‚îú‚îÄ‚îÄ model/             # Artifacts du mod√®le
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt   # D√©pendances ML
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile         # Image Docker
‚îú‚îÄ‚îÄ scoreapi/              # API REST FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ app/main.py       # Endpoints s√©curis√©s
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt  # D√©pendances API
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile        # Image Docker
‚îú‚îÄ‚îÄ auditfairness/        # Dashboard Dash
‚îÇ   ‚îú‚îÄ‚îÄ app/dashboard.py  # Interface de monitoring
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt  # D√©pendances dashboard
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile        # Image Docker
‚îî‚îÄ‚îÄ README.md             # Documentation compl√®te
```

### Guidelines de D√©veloppement

1. **Code Quality** : Tests unitaires obligatoires
2. **Documentation** : Docstrings et commentaires
3. **Security** : Scan des vuln√©rabilit√©s
4. **Performance** : Profiling des services critiques

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üôã‚Äç‚ôÇÔ∏è Support

### Documentation Suppl√©mentaire
- [Architecture Decision Records](docs/adr/)
- [API Documentation](docs/api/)
- [Deployment Guide](docs/deployment/)
- [Troubleshooting Guide](docs/troubleshooting/)

### Contacts
- **√âquipe Technique** : tech-team@healthflow.com
- **Support** : support@healthflow.com
- **S√©curit√©** : security@healthflow.com

---

**HealthFlow-MS** - *Transforming Healthcare through Intelligent Risk Assessment*


## ‚ùì O√π ins√©rer des donn√©es ? (Where to insert data)

Selon votre besoin, il existe trois fa√ßons d‚Äôalimenter le syst√®me:

1) Chemin recommand√© (r√©aliste) ‚Äî via ProxyFHIR et le serveur FHIR public
- Objectif: Ingestion FHIR r√©elle puis pipeline EDA (Kafka) jusqu‚Äôaux scores.
- √âtapes:
  - D√©marrer la stack: docker compose up -d --build
  - Choisir un Patient ID valide depuis https://hapi.fhir.org/baseR4 (ex. un id que vous voyez via l‚ÄôUI HAPI)
  - Ingestion: curl -X POST http://localhost:8081/api/v1/fhir/sync/patient/<PATIENT_ID>
  - Le service ProxyFHIR √©crit le bundle brut dans PostgreSQL (table fhir_bundles) et publie un message dans Kafka (fhir.data.raw).
  - DeID, Featurizer, ModelRisque consomment en cha√Æne et finissent par √©crire les r√©sultats dans prediction_results.

2) Chemin d√©veloppeur ‚Äî via Kafka (pipeline simul√©)
- Objectif: Tester une partie du pipeline sans le FHIR externe.
- R√©f√©rence: scripts/test_pipeline.sh (exemple de test bout‚Äë√†‚Äëbout). Vous pouvez publier manuellement dans les topics Kafka si n√©cessaire.
- Kafka interne pour les services: kafka:9092 (h√¥te: localhost:9094)
- Topics cl√©s: fhir.data.raw ‚Üí fhir.data.anonymized ‚Üí features.patient.ready ‚Üí risk.score.calculated

3) Chemin rapide (d√©mo/UX) ‚Äî injection directe en base
- Objectif: Voir imm√©diatement des scores dans ScoreAPI et des graphiques dans le dashboard sans attendre le pipeline.
- Commande:
  - bash scripts/seed_sample_data.sh
- Ce script ins√®re quelques lignes r√©alistes dans la table prediction_results.
- V√©rification rapide:
  - docker compose exec postgres psql -U healthflow -d healthflow -c "SELECT patient_pseudo_id, risk_score, prediction_timestamp FROM prediction_results ORDER BY prediction_timestamp DESC LIMIT 10;"
- Ensuite:
  - ScoreAPI: http://localhost:8082/docs (GET /api/v1/score/{patient_pseudo_id})
  - Dashboard: http://localhost:8083 (mettre DASH_DEMO_MODE=0 dans docker-compose.yml pour d√©sactiver le mode d√©mo)

Notes importantes
- fhir_bundles (brut) est aliment√©e uniquement par ProxyFHIR. N‚Äôins√©rez pas directement des bundles bruts sauf cas de test contr√¥l√©.
- prediction_results est la table lue par ScoreAPI et AuditFairness. Pour des d√©monstrations rapides, l‚Äôinjection directe via scripts/seed_sample_data.sh est la plus simple.
- S√©curit√©: ScoreAPI requiert un JWT pour les endpoints prot√©g√©s. G√©n√©rez un token via POST /auth/token (voir section ¬´ Test du Pipeline Complet ¬ª ci‚Äëdessus).


## üß∞ Gestion des nouvelles donn√©es (DataManager)

Le service DataManager permet d‚Äôajouter, modifier, supprimer et lister des r√©sultats de pr√©diction, ainsi que de d√©clencher l‚Äôingestion FHIR manuellement.

- UI de documentation: http://localhost:8084/docs
- Port conteneur: 8001 (expos√© en 8084 c√¥t√© h√¥te)

Endpoints cl√©s (tous prot√©g√©s par JWT):
- POST /auth/token ‚Üí g√©n√®re un token de d√©veloppement (√† utiliser en Authorization: Bearer ...)
- POST /api/v1/predictions ‚Üí cr√©er une ligne dans prediction_results
- GET /api/v1/predictions ‚Üí lister
- GET /api/v1/predictions/{id} ‚Üí r√©cup√©rer par id
- PUT /api/v1/predictions/{id} ‚Üí mettre √† jour
- DELETE /api/v1/predictions/{id} ‚Üí supprimer
- POST /api/v1/ingest/patient/{patient_id} ‚Üí relayer une ingestion vers ProxyFHIR

Exemples rapides:
```bash
# 1) Obtenir un token (dev)
TOKEN=$(curl -s -X POST http://localhost:8084/auth/token | jq -r .access_token)

# 2) Cr√©er un r√©sultat de pr√©diction
curl -s -X POST http://localhost:8084/api/v1/predictions \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "patient_pseudo_id": "PSEUDO_DEMO_1",
    "risk_score": 0.73,
    "prediction_confidence": 0.85,
    "shap_values_json": {"age": 0.02, "heart_rate_mean": 0.04},
    "feature_vector_json": {"age": 67, "heart_rate_mean": 82},
    "model_version": "v1.0"
  }'

# 3) V√©rifier via ScoreAPI (utiliser le token ScoreAPI si configur√©)
curl -s http://localhost:8082/docs

# 4) Voir dans le dashboard (mettre DASH_DEMO_MODE=0 pour afficher uniquement les donn√©es r√©elles)
open http://localhost:8083
```

S√©curit√©: en production, configurez un SECRET distinct (JWT_SECRET_KEY) et d√©sactivez l‚Äôendpoint /auth/token. 
